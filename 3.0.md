#### Version: 3.0


This document was built on top of the Activity Schema documentation [Version 2.0](https://github.com/ruhragency/ActivitySchema/blob/main/2.0.md)

# Purpose of this documention/project

This document is designed for software developers who are responsible for implementing both the user interface (UI) and backend of the self-service Business Intelligence (BI) system, incorporating the following functionalities:

1. Connect to a database containing the target customer_stream
2. Provide a page where users can browse all activites and their general information (Example: names, fields, number of rows under the activity ...)
3. Canvas to construct simple queries involving one activity table at a time and generate a desired dataset.(See [Basic Queries](#basic-queries))
4. For [Advanced Queries](#advanced-queries) combining/joing different activities, two UI components have to be present:
	- Provide a page describing all available relationships to construct queries along with examples. 
	- Page to model such queries (whether drag and drop, or just select from a drop down list as shown in the screenshot bellow)

![construct_advanced_join](https://github.com/ruhragency/ActivitySchema/assets/144046348/a603ade5-1d24-4305-9ea6-efcfd3fe0893)

As opposed to v2 of the activity schema, this document will provide template SQL queries to build the desired datasets, clearly define each temporal join, and show how/when to use each relationship via examples.

# What is an activity schema?

An Activity Schema data model is a new paradigm designed for modern data warehouses. It was initially created and implemented by [Ahmed Elsamadisi](https://www.linkedin.com/in/elsamadisi/).


This new standard for data enables:

1. Standardized data modeling accross industry, sector and use-case
2. A simpler structure that is easily understandable
3. A warehouse-native solution for modeling data.


<br>

The Activity Schema model aims for these design goals

- **only one definition for each concept** - know exactly where to find the right data
- **single model layer** - no layers of dependencies
- **simple definitions** - no thousand-line SQL queries to model data
- **no relationships in the modeling laye**r - all concepts are defined independently of each other
- **no foreign key joins -** all concepts can be joined together without having to identify how they relate in advance
- **analyses can be run anywhere** — analyses can be shared and reused across companies with vastly different data.
- **high performance** - reduced joins and fewer columns leverages the power of modern column-oriented data warehouses
- **incremental updates** - no more rebuilding data models on every update
- **dynamically queried at analysis time** - create any table at the moment you need it

<br>


At its core an activity schema approach consists of transforming raw tables into a time series table called an Activity Stream. All downstream plots, tables, materialized views, etc used for BI are built **directly** from that table, with no other dependencies.

<br>

![Overall Diagram](https://user-images.githubusercontent.com/1216989/206594538-a6d5ca01-cd6a-4eab-94ce-9854531288eb.png)


<br>


To understand how the activity stream is modeled, the table structure, the entities, activities, and all naming conventions, please refer to the sections: [Conceptual Overview](https://github.com/ruhragency/ActivitySchema/blob/main/3.0.md#conceptual-overview), [Structure](https://github.com/ruhragency/ActivitySchema/blob/main/3.0.md#structure), and [Managing an Activity Schema](https://github.com/ruhragency/ActivitySchema/blob/main/3.0.md#managing-an-activity-schema)

In the [Activity stream table definition](#activity-stream-table-definition) section bellow, we provide a sample query to create a customer_stream tabele on Databricks. We also present an example of how to generate an activity from an existing order line view.

 
# Activity stream table definition

In general, we will follow the `three-tier` architecture to design this App.
In the `data tier`, we will always refer to the activity stream as the `customer_stream`. This alligns with the specs of the activity schema. It also means that we will always query one single table. 
Sub-tables or views that will be joined to construct complex queries will be derived by filtering the customer_stream with the target activity name. 
The customer_stream will have 5 mandatory columns: `activity_id` a unique row identifier, `ts` as the timestamp of the activity, `customer` most of the time email of the customer, `activity` as the activity name, and the `feature_json` a compressed structure containing further information about the row entry. Bellow is the query to instantiate a the activity stream table in Databricks.

```sql

CREATE OR REPLACE TABLE customer_stream (
    activity_id STRING,
    ts timestamp,
    customer STRING,
    activity STRING,
    feature_json MAP<STRING, ARRAY<STRING>>
)

```

Once the table is ready, we can populate it with new activities from the data warehouse as needed. Bellow is an example of adding the ctivity `placed_order` derived from an order line deep dive table of an e-commerce business data warehouse.

```sql

WITH placed_order_table AS (
  SELECT order_id, fulfillment_status_tracked, financial_status_tracked, updated_at
  FROM (
      SELECT order_id, fulfillment_status_tracked, financial_status_tracked, updated_at,
          ROW_NUMBER() OVER (PARTITION BY order_id, fulfillment_status_tracked ORDER BY updated_at) AS row_num
      FROM deep_dive_table
      WHERE fulfillment_status_tracked IS NULL
  ) ranked
  WHERE row_num = 1
)

INSERT INTO customer_stream
SELECT
    UUID() AS activity_id,
    MAX(filter_table.updated_at) AS ts,
    MAX(base.email) AS customer,
    'placed_order' AS activity,
    MAP(
        'order_id', ARRAY_AGG(DISTINCT filter_table.order_id),
        'shipping_method', ARRAY_AGG(DISTINCT shipping_method),
		
		'product_names', COLLECT_LIST(CASE WHEN product_name IS NOT NULL THEN product_name ELSE "-" END),
        'discount_code', COLLECT_LIST(CASE WHEN discount_code IS NOT NULL THEN discount_code ELSE "-" END),
        'item_type', COLLECT_LIST(CASE WHEN item_type IS NOT NULL THEN item_type ELSE "-" END),
        'original_price', COLLECT_LIST(CASE WHEN original_price IS NOT NULL THEN original_price ELSE 0 END),
        'gross_selling_price', COLLECT_LIST(CASE WHEN gross_selling_price IS NOT NULL THEN gross_selling_price ELSE 0 END),
        'net_selling_price', COLLECT_LIST(CASE WHEN net_selling_price IS NOT NULL THEN net_selling_price ELSE 0 END),
        'tax_rate', COLLECT_LIST(CASE WHEN tax_rate IS NOT NULL THEN tax_rate ELSE 0 END ),
        'cost_price', COLLECT_LIST(CASE WHEN cost_price IS NOT NULL THEN cost_price ELSE 0 END), 
        'quantity', COLLECT_LIST(CASE WHEN quantity IS NOT NULL THEN quantity ELSE 0 END)
    ) AS feature_json
FROM deep_dive_table AS base
INNER JOIN placed_order_table AS filter_table
	ON base.order_id = filter_table.order_id AND base.updated_at = filter_table.updated_at
GROUP BY base.order_id

```


# Querying

The structure of an activity schema deviates in certain fundamental aspects from more conventional approaches.

1. data is in a time-series format
2. queries only select from the activity stream table (and optionally join in dimension tables)
3. any activity can be related (joined) to any other activity using only the entity and timestamp

This means that querying is a bit different but substantially more powerful. 

An activity schema **does not require any foreign key joins.** All joins are self-joins to the customer_stream table, and they only use the entity and timestamp columns. This means there is **always** a way to relate **any data** in an activity schema to anything else. 

Another way of phrasing this is that

1. Any query can substitute different activities by merely changing the activity name(s) where present in the query
2. Any query can be run on any activity schema implementation (say at a different company) by substituting activities if necessary

> This means that someone could build a customer lifetime value analysis, and run it on any number of companies' data with minimal modification.

Or one could compute the conversion rate over time of one activity to another (what percent of signups converted to orders) then quickly substitute the activities to answer a related question (what percent of orders converted to another order). In existing approaches, this usually requires restructuring the query, and in some cases in-depth work to find the right foreign keys to join. 

Lastly, a consistent table structure coupled with easily-modified queries means that it is far more useful to automatically generate SQL than before. An activity schema is best queried by specifying which kinds of activities and relationships matter and allowing a system to generate the actual SQL. 

In general, we can classify the queries into 2 categories: 

- [Basic Queries](#basic-queries): Leveraging a single table/view.
- [Advanced Queries](#advanced-queries): Incorporating joins to construct complex queries.
  
<br>
<br>

# Basic Queries

Simple queries are largely the same. Let's take a hypothetical bike-sharing company as an example. The monthly number of day passes sold, along with revenue, is pretty straightforward.

```sql

SELECT
	customer,
	DATE_TRUNC('month', ts) AS month,
	COUNT(activity_id) as total_orders
FROM customer_stream AS c
WHERE c.activity = 'placed_order'

GROUP BY customer, month
ORDER BY customer, month

```

<br>

It's fairly obvious that counting total order returns instead of total placed orders simply requires substituting '**placed_order**' with '**returned_order**'.  

```sql

SELECT
	customer,
	DATE_TRUNC('month', ts) AS month,
	COUNT(activity_id) as total_orders
FROM customer_stream AS c
WHERE c.activity = 'placed_order'

GROUP BY customer, month
ORDER BY customer, month

```

Now let's see how this works when relating multiple activities together. 

<br>

# Advanced Queries

Relating multiple activities together is done by joining the single activity stream table to itself using the customer identifier and timestamps. Since these two things are present on all activities, swapping out different activities will still work. 

We name those joins relationships:

## Relationships

The activity schema is designed around customers and timestamps instead of foreign keys. As a result, in-depth querying requires a different way of thinking.

**Relationships** are a concept designed express all the ways activities can relate (i.e. be joined) with each other. 

For example, the data question 'which email did a user open before completing an order' can be expressed as a 'last before' relationship. "For each 'Completed Order', find the last 'Opened Email' before that order". 

Relationships are intended to be used to query the activity schema -- through a tool that reads the relationships and generates and runs SQL against the activity stream tables. This language helps express joins that can't be done easily with SQL directly. Once they are expressed as relationships, translating into actual SQL is straightforward. 

Relationships have two parts: an initial **cohort** activity, and one or more **append** activities brought in with a specific relationship.

<br>

### The Cohort Activity

The cohort is the primary activity in a query. It defines the rows in the result table. In the example above the cohort activity is 'completed_order' or 'placed_order'. 

Each activity appended to the cohort activity via a relationship will simply add *columns* to the result table. Appending activities via relationships will never change the rows returned -- it will never duplicate or drop rows. A cohort is roughly analogous to a FROM in SQL, while each relationship to an append activity can be thought of as a LEFT JOIN.  

For examples below, we will use **placed_order** as the cohort(primary) activity. 

<br>

### All relationships

In order to build an advanced query, the user will have to provide a `primary_activity`, an `append_activity`, and select the type of `relationship` (also referred to as the `temporal join` relationship). 
Values from the append_activity are appended as append_columns, while maintaining the number of rows in the primary_activity view. We introduce a total of 13 relationships which would dictate most possible queries to make on your customer_stream table. 
Possible queries to execute on our customer_stream table will be outlined below, accompanied by detailed explanations and the corresponding SQL queries to perform the joins. It is important to note that when we refer to `before` or `after`, it is **strictly** as stated unless otherwise specified:

<br>

**1. First Ever:** Appends the FIRST EVER append activity for each customer in your dataset, regardless of when the primary activity occurred.

 Three parameters have to be provided to generate the view:  `<entity>_stream`, `<primary_activity_name>`, `<append_activity_name>`

In the example of identifying the start of a customer journey, we want to get the first ever "opened session" of customers who "placed orders". 
In this scenario:
- `<entity>_stream` = customer_stream
- `<primary_activity_name>` = placed_order 
- `<append_activity_name>` = opened_session


```sql
WITH first_ever AS ( 
    SELECT *, 
           ROW_NUMBER() OVER (PARTITION BY append.customer ORDER BY append.ts) AS row_num 
    FROM <entity>_stream AS append 
    WHERE append.activity = <append_activity_name> 
)

SELECT *
FROM <entity>_stream AS primary
LEFT JOIN first_ever AS append
    ON (primary.customer = append.customer AND append.row_num = 1)
WHERE primary.activity = <primary_activity_name>

```
Please be aware that we fetch all columns for both the primary and appended tables. Users have the flexibility to choose the final columns as well as any custom column names.
	
<br>

**2. First Before:** Appends the FIRST append activity, but only if it happened BEFORE the primary activity.

 Three parameters have to be provided to generate the view:  `<entity>_stream`, `<primary_activity_name>`, `<append_activity_name>`

Let's assume that new customer aquisition is made through marketing compaingns advertised in social media where users enter contact information, you want to get the first time the customer 'opened session' after he 'opened email' sent.
In this scenario:
- `<entity>_stream` = customer_stream
- `<primary_activity_name>` = opened_session 
- `<append_activity_name>` = opened_email

```sql
WITH first_before AS (
    SELECT 
        primary.*, 
        append.ts as append_ts,
        ROW_NUMBER() OVER (PARTITION BY primary.activity_id ORDER BY append.ts) AS row_num
    FROM <entity>_stream AS primary
    INNER JOIN <entity>_stream AS append 
		ON primary.customer = append.customer 
    WHERE primary.activity = <primary_activity_name>
            AND append.activity = <append_activity_name>
            AND append.ts < primary.ts
)

SELECT primary.*,
        append_ts
FROM <entity>_stream AS primary
LEFT JOIN first_before AS append
	ON (primary.activity_id = append.activity_id AND append.row_num = 1)
WHERE primary.activity = <primary_activity_name>

```

Please be aware that we fetched only the timestamp of the first before append activity relative to the current timestamp of the primary activity. 
Users can have the flexibility to choose the columns to fetch as well as any custom column names. Such custom definitions can be defined in the CTE first.

<br>

**3. First After:** This relationship adds the FIRST time the append activity happened AFTER the primary activity.

Three parameters have to be provided to generate the view:  `<entity>_stream`, `<primary_activity_name>`, `<append_activity_name>`

Let's assume you are interested in a dataset with the next 'placed_order' after the current order. This is a special example where you will have to join the same view with itslef. 
In this scenario:
- `<entity>_stream` = customer_stream
- `<primary_activity_name>` = placed_order 
- `<append_activity_name>` = placed_order

```sql
WITH first_after AS (
    SELECT 
        primary.*, 
        append.ts as append_ts,
        ROW_NUMBER() OVER (PARTITION BY primary.activity_id ORDER BY append.ts) AS row_num
    FROM <entity>_stream AS primary
    INNER JOIN <entity>_stream AS append 
		ON primary.customer = append.customer 
    WHERE primary.activity = <primary_activity_name>
            AND append.activity = <append_activity_name>
            AND append.ts > primary.ts
)

SELECT primary.*,
        append_ts
FROM <entity>_stream AS primary
LEFT JOIN first_after AS append
	ON (primary.activity_id = append.activity_id AND append.row_num = 1)
WHERE primary.activity = <primary_activity_name>

```

Please be aware that we fetched only the timestamp of the first before append activity relative to the current timestamp of the primary activity. 
Users can have the flexibility to choose the columns to fetch as well as any custom column names. Such custom definitions can be defined in the CTE first.

<br>

**4. First In Between:** Appends the FIRST append activity that happened IN BETWEEN that primary activity and the next instance of the primary activity.

Three parameters have to be provided to generate the view:  `<entity>_stream`, `<primary_activity_name>`, `<append_activity_name>`

One of the examples in event-based conversion is to check whether the customer has 'placed an order' before he 'opens a session' the next time.
In this scenario:
- `<entity>_stream` = customer_stream
- `<primary_activity_name>` = opened_session 
- `<append_activity_name>` = placed_order


```sql

WITH PrimaryWithNextTS AS (
    SELECT 
        primary.*, 
        LEAD(primary.ts) OVER (PARTITION BY primary.customer ORDER BY primary.ts) AS next_ts
    FROM <entity>_stream AS primary
    WHERE primary.activity = <primary_activity_name>
), first_in_between AS (
    SELECT 
        primary.*, 
        append.ts as append_ts,
        ROW_NUMBER() OVER (PARTITION BY primary.activity_id ORDER BY append.ts) AS row_num
    FROM PrimaryWithNextTS AS primary
    INNER JOIN <entity>_stream AS append 
		ON primary.customer = append.customer 
    WHERE append.activity = <append_activity_name>
        AND append.ts > primary.ts
        AND append.ts < primary.next_ts
)

SELECT primary.*,
        append_ts
FROM <entity>_stream AS primary
LEFT JOIN first_in_between AS append
	ON (primary.activity_id = append.activity_id AND append.row_num = 1)
WHERE primary.activity = <primary_activity_name>

```

Please be aware that we fetched only the timestamp of the first (strictly) in between append activity relative to the current timestamp of the primary activity , and its next one. 
Users can have the flexibility to choose the columns to fetch as well as any custom column names. Such custom definitions can be defined in the CTE first.

<br>

**5. Last Ever:** Appends the LAST EVER append activity for each customer in your dataset, regardless of when the primary activity occurred.

Three parameters have to be provided to generate the view:  `<entity>_stream`, `<primary_activity_name>`, `<append_activity_name>`

Let's say you want to analyse the customer satisfaction of customers by generating a dataset of the last time ever a customer 'filed a complaint' after he made a purchase.
In this scenario:
- `<entity>_stream` = customer_stream
- `<primary_activity_name>` = placed_order 
- `<append_activity_name>` = filed_complaint

```sql

WITH last_ever AS ( 
    SELECT *, 
           ROW_NUMBER() OVER (PARTITION BY append.customer ORDER BY append.ts DESC) AS row_num 
    FROM <entity>_stream AS append 
    WHERE append.activity = <append_activity_name> 
)

SELECT *,
	   append.ts as append_ts
FROM <entity>_stream AS primary
LEFT JOIN last_ever AS append
    ON (primary.customer = append.customer AND append.row_num = 1)
WHERE primary.activity = <primary_activity_name>

```

Please be aware that we fetched only the timestamp of the last ever append activity relative to the current timestamp of the primary activity. 
Users can have the flexibility to choose the columns to fetch as well as any custom column names.


<br>

**6. Last Before:** Appends the LAST append activity that happened BEFORE the primary activity.

Three parameters have to be provided to generate the view:  `<entity>_stream`, `<primary_activity_name>`, `<append_activity_name>`

Let's say you are interested in a dataset in which you see the last time a customer has updated his shipping address (might be useful to analyse slowly changing dimenssions).
In this scenario:
- `<entity>_stream` = customer_stream
- `<primary_activity_name>` = opened_session 
- `<append_activity_name>` = updated_personal_information

```sql

WITH last_before AS (
    SELECT 
        primary.*, 
        append.ts as append_ts,
        ROW_NUMBER() OVER (PARTITION BY primary.activity_id ORDER BY append.ts DESC) AS row_num
    FROM <entity>_stream AS primary
    INNER JOIN <entity>_stream AS append 
		ON primary.customer = append.customer 
    WHERE primary.activity = <primary_activity_name>
            AND append.activity = <append_activity_name>
            AND append.ts < primary.ts
)

SELECT primary.*,
        append_ts
FROM <entity>_stream AS primary
LEFT JOIN last_before AS append
	ON (primary.activity_id = append.activity_id AND append.row_num = 1)
WHERE primary.activity = <primary_activity_name>

```

Please be aware that we fetched only the timestamp of the last before append activity relative to the current timestamp of the primary activity. 
Users can have the flexibility to choose the columns to fetch as well as any custom column names.

<br>

**7. Last After:** This relationship adds the LAST time the append activity happened AFTER the primary activity.

Three parameters have to be provided to generate the view:  `<entity>_stream`, `<primary_activity_name>`, `<append_activity_name>`

Let's say you want to analyse the customer dissatisfaction by generating a dataset of the last time a customer 'returned a purchase' after he made an order.
In this scenario:
- `<entity>_stream` = customer_stream
- `<primary_activity_name>` = placed_order 
- `<append_activity_name>` = returned_order

```sql

WITH last_after AS (
    SELECT 
        primary.*, 
        append.ts as append_ts,
        ROW_NUMBER() OVER (PARTITION BY primary.activity_id ORDER BY append.ts DESC) AS row_num
    FROM <entity>_stream AS primary
    INNER JOIN <entity>_stream AS append 
		ON primary.customer = append.customer 
    WHERE primary.activity = <primary_activity_name>
            AND append.activity = <append_activity_name>
            AND append.ts > primary.ts
)

SELECT primary.*,
        append_ts
FROM <entity>_stream AS primary
LEFT JOIN last_after AS append
	ON (primary.activity_id = append.activity_id AND append.row_num = 1)
WHERE primary.activity = <primary_activity_name>

```

Please be aware that we fetched only the timestamp of the last after append activity relative to the current timestamp of the primary activity. 
Users can have the flexibility to choose the columns to fetch as well as any custom column names.

<br>

**8. Last In Between:** Appends the LAST append activity that happened IN BETWEEN that primary activity and the next instance of the primary activity.

Three parameters have to be provided to generate the view:  `<entity>_stream`, `<primary_activity_name>`, `<append_activity_name>`

You want to understand the customer user experience on your website, so you want to check the last page the customer visits before the next time he opens a session.
In this scenario:
- `<entity>_stream` = customer_stream
- `<primary_activity_name>` = opened_session 
- `<append_activity_name>` = visited_page

In this case the feature_json payload will contain information about the visted page.

```sql

WITH PrimaryWithNextTS AS (
    SELECT 
        primary.*, 
        LEAD(primary.ts) OVER (PARTITION BY primary.customer ORDER BY primary.ts) AS next_ts
    FROM <entity>_stream AS primary
    WHERE primary.activity = <primary_activity_name>
), first_in_between AS (
    SELECT 
        primary.*, 
        append.ts as append_ts,
        ROW_NUMBER() OVER (PARTITION BY primary.activity_id ORDER BY append.ts DESC) AS row_num
    FROM PrimaryWithNextTS AS primary
    INNER JOIN <entity>_stream AS append 
		ON primary.customer = append.customer 
    WHERE append.activity = <append_activity_name>
        AND append.ts > primary.ts
        AND append.ts < primary.next_ts
)

SELECT primary.*,
        append_ts
FROM <entity>_stream AS primary
LEFT JOIN first_in_between AS append
	ON (primary.activity_id = append.activity_id AND append.row_num = 1)
WHERE primary.activity = <primary_activity_name>

```

Please be aware that we fetched only the timestamp of the first (strictly) in between append activity relative to the current timestamp of the primary activity , and its next one. 
Users can have the flexibility to choose the columns to fetch as well as any custom column names. Such custom definitions can be defined in the CTE first.

<br>

**9. Aggregate All Ever:** Appends an AGGREGATION of ALL the append activities that happened EVER regardless of when the primary activity occurred.

Three parameters have to be provided to generate the view:  `<entity>_stream`, `<primary_activity_name>`, `<append_activity_name>`

On the same line of customer satisfaction analysis, you want to know the total number of returns made by clients.
In this scenario:
- `<entity>_stream` = customer_stream
- `<primary_activity_name>` = placed_order 
- `<append_activity_name>` = returned_order
- The aggregate function will be: count(*)

```sql

WITH aggregate_all_ever AS (
    SELECT 
        append.customer,
		count(*) AS total --Change to desired aggregate function
    FROM <entity>_stream AS append
    WHERE activity = <append_activity_name>
    GROUP BY append.customer 
)

SELECT primary.*,
       CASE WHEN total is NULL THEN 0 ELSE total END AS aggregate_result
FROM <entity>_stream AS primary
LEFT JOIN aggregate_all_ever AS append
	ON primary.customer = append.customer
WHERE primary.activity = <primary_activity_name>

```

Be aware that in this query template, we used the example of count() aggreagte function. 
Users can replace this function by defining their own aggreagation according to their needs.
Users can have the flexibility to choose the columns to fetch as well as any custom column names. 

<br>

**10. Aggregate Before:** Appends an AGGREGATION of all the append activities that happened BEFORE the primary activity occurred.

Three parameters have to be provided to generate the view:  `<entity>_stream`, `<primary_activity_name>`, `<append_activity_name>`

Let's assume you want to generate a dataset to know how many orders were made by the customer, before he returns a purchase.
In this scenario:
- `<entity>_stream` = customer_stream
- `<primary_activity_name>` = returned_order 
- `<append_activity_name>` = placed_order
- The aggregate function will be: count(*)

```sql

WITH aggregate_before AS (
    SELECT 
        primary.activity_id,
		count(*) AS total--Change to desired aggregate function
    FROM <entity>_stream AS primary
    INNER JOIN <entity>_stream AS append
        ON primary.customer = append.customer
    WHERE primary.activity = <primary_activity_name>
        AND append.activity = <append_activity_name>
        AND append.ts < primary.ts
    GROUP BY primary.activity_id
)

SELECT primary.*,
        CASE WHEN total is NULL THEN 0 ELSE total END AS aggregate_result
FROM <entity>_stream AS primary
LEFT JOIN aggregate_before AS append
    ON (primary.activity_id = append.activity_id)
WHERE primary.activity = <primary_activity_name>

```

Be aware that in this query template, we used the example of count() aggreagte function to aggregate entires from the append activity strictly before the primary activity. 
Users can replace this function by defining their own aggreagation according to their needs.
Users can have the flexibility to choose the columns to fetch as well as any custom column names. 

<br>

**11. Aggregate After:** Appends an AGGREGATION of ALL the append activities that happened AFTER the primary activity occurred (opposite of Aggregate Before).

Three parameters have to be provided to generate the view:  `<entity>_stream`, `<primary_activity_name>`, `<append_activity_name>`

Now you want to analyse the impact of returning a purchse(customer dissatisfaction) on the next placed orders.
In this scenario:
- `<entity>_stream` = customer_stream
- `<primary_activity_name>` = returned_order 
- `<append_activity_name>` = placed_order
- The aggregate function will be: count(*)

```sql

WITH aggregate_after AS (
    SELECT 
        primary.activity_id, 
		count(*) AS total--Change to desired aggregate function    
	FROM <entity>_stream AS primary
    INNER JOIN <entity>_stream AS append
        ON primary.customer = append.customer
    WHERE primary.activity = <primary_activity_name>
        AND append.activity = <append_activity_name>
        AND append.ts > primary.ts
    GROUP BY primary.activity_id 
)

SELECT primary.*,
       CASE WHEN total is NULL THEN 0 ELSE total END AS aggregate_result
FROM <entity>_stream AS primary
LEFT JOIN aggregate_after AS append
    ON (primary. activity_id = append. activity_id)
WHERE primary.activity = <primary_activity_name>

```

Be aware that in this query template, we used the example of count() aggreagte function to aggregate entires from the append activity strictly after the primary activity. 
Users can replace this function by defining their own aggreagation according to their needs.
Users can have the flexibility to choose the columns to fetch as well as any custom column names. 

<br>

**12. Aggregate First After:** Appends an AGGREGATION computing some metric of the the FIRST time the append activity happened AFTER the primary activity.

Three parameters have to be provided to generate the view:  `<entity>_stream`, `<primary_activity_name>`, `<append_activity_name>`

This is a very useful join that can be used a lot to compute the time required for the append activity to happen after the primary activity.
An exmaple of such use cases, in the e-commerce industry, is the repurchase rate, which we show cased in the template bellow using the following aggregate function: DATEDIFF(append_ts, ts).

**[append_ts stands for the timestamp (ts) of the FIRST after append activity with regard to the ts of the primary activity]**. 

In this scenario:
- `<entity>_stream` = customer_stream
- `<primary_activity_name>` = placed_order 
- `<append_activity_name>` = placed_order

```sql

WITH _first_after AS (
    SELECT 
        primary.*, 
        append.ts as append_ts,
        ROW_NUMBER() OVER (PARTITION BY primary.activity_id ORDER BY append.ts) AS row_num
    FROM <entity>_stream AS primary
    INNER JOIN <entity>_stream AS append 
		ON primary.customer = append.customer 
    WHERE primary.activity = <primary_activity_name>
            AND append.activity = <append_activity_name>
            AND append.ts > primary.ts
), aggreagte_first_after AS (
    SELECT activity_id,
			append_ts,
			ROUND(DATEDIFF(append_ts, ts), 2) AS total--Change to desired aggregate function
	FROM _first_after
    WHERE row_num = 1
	GROUP BY activity_id, ts, append_ts
)

SELECT primary.*,
        append_ts AS first_after_ts,
		CASE WHEN total is NULL THEN 0 ELSE total END AS aggregate_result
FROM <entity>_stream AS primary
LEFT JOIN aggreagte_first_after AS append
	ON primary.activity_id = append.activity_id
WHERE primary.activity = <primary_activity_name>


```

Users can replace the aggregate function by defining their own aggreagation according to their needs. Users can have the flexibility to choose the columns to fetch as well as any custom column names. 

<br>

**13. Aggregate In Between:** Appends an AGGREGATION of all the append activities that happened IN BETWEEN that primary activity and the next instance of the primary activity.

Three parameters have to be provided to generate the view:  `<entity>_stream`, `<primary_activity_name>`, `<append_activity_name>`


```sql

WITH PrimaryWithNextTS AS (
    SELECT 
        primary.*, 
        LEAD(primary.ts) OVER (PARTITION BY primary.customer ORDER BY primary.ts) AS next_ts
    FROM <entity>_stream AS primary
    WHERE primary.activity = <primary_activity_name>

), aggregate_in_between AS (
    SELECT 
        primary.activity_id, 
		count(*) AS total--Change to desired aggregate function
    FROM PrimaryWithNextTS AS primary
    INNER JOIN <entity>_stream AS append
        ON primary.customer = append.customer
    WHERE append.activity = <append_activity_name>
        AND append.ts < primary.next_ts 
        AND append.ts > primary.ts
    GROUP BY primary.activity_id 
)

SELECT primary.*,
       CASE WHEN total is NULL THEN 0 ELSE total END AS aggregate_result
FROM <entity>_stream AS primary
LEFT JOIN aggregate_in_between AS append
    ON (primary. activity_id = append. activity_id)
WHERE primary.activity = <primary_activity_name>

```

Be aware that in this query template, we used the example of count() aggreagte function to aggregate the in between entires from the append activity relative to the current timestamp of the primary activity and its next entry.
Users can replace the aggregate function by defining their own aggreagation according to their needs. Users can have the flexibility to choose the columns to fetch as well as any custom column names. 

<br>

> This set of relationships is sufficient to query anything from the activity schema. Some are more commonly used and some other temporal jions are less commonly used, such as **Last After**, **First Before**, and **Last In Between**.


<br>

## Enriching datasets with multiple temporal joins

Let's say you want to analyse in depth the effect of customer dissatisfaction (identified by a returned order from a customer), on their purchase experience, especialy in the future.
- First you want to identify the cohort/primary activity, and that is the 'returned_order'
- Second, you want to see how many orders customers made before this return (We will need obviously the 'Aggregate Before')
- Third, you want to see how many orders customers made after (We will need the 'Aggregate After')
- Fourth, you want to get the date/time when they started ordering again after this incident (We will need the 'First After')

The 'primary_activity' always stays  the same for all the joins, 'returned_order'. What you need to identify is the 'append_activity' for each join, and the aggregate function for the 'Aggregate' joins.
In this scenario, all `<append_activity_name>`s for all 3 joins are the same 'placed_order'. The aggregate function is also the same, 'count(*)'.
The final query will then be (replace by the activity names): 


```sql

WITH aggregate_before AS (
    SELECT 
        primary.activity_id,
		count(*) AS total
    FROM <entity>_stream AS primary
    INNER JOIN <entity>_stream AS append
        ON primary.customer = append.customer
    WHERE primary.activity = <primary_activity_name>
        AND append.activity = <append_activity_name>
        AND append.ts < primary.ts
    GROUP BY primary.activity_id
), aggregate_after AS (
    SELECT 
        primary.activity_id, 
		count(*) AS total    
	FROM <entity>_stream AS primary
    INNER JOIN <entity>_stream AS append
        ON primary.customer = append.customer
    WHERE primary.activity = <primary_activity_name>
        AND append.activity = <append_activity_name>
        AND append.ts > primary.ts
    GROUP BY primary.activity_id 
), first_after AS (
    SELECT 
        primary.*, 
        append.ts as append_ts,
        ROW_NUMBER() OVER (PARTITION BY primary.activity_id ORDER BY append.ts) AS row_num
    FROM <entity>_stream AS primary
    INNER JOIN <entity>_stream AS append 
		ON primary.customer = append.customer 
    WHERE primary.activity = <primary_activity_name>
            AND append.activity = <append_activity_name>
            AND append.ts > primary.ts
)


SELECT primary.*,
        CASE WHEN append_1.total is NULL THEN 0 ELSE append_1.total END AS made_purchases_before,
        CASE WHEN append_2.total is NULL THEN 0 ELSE append_2.total END AS made_purchases_after,
        append_3.append_ts AS next_purchase_date
		
FROM <entity>_stream AS primary

LEFT JOIN aggregate_before AS append_1
    ON (primary.activity_id = append_1.activity_id)
LEFT JOIN aggregate_after AS append_2
    ON (primary. activity_id = append_2. activity_id)
LEFT JOIN first_after AS append_3
    ON (primary.activity_id = append_3.activity_id AND append_3.row_num = 1)

WHERE primary.activity = <primary_activity_name>


```

The structure of combining multiple joins is trivial as shown in the above example.
You just need to append the Common Table Expressions (CTEs) in one WITH clause using a comma, for each of the temporal join templates defined earlier.
Later when fetching the results, you just LEFT JOIN each append (CTE) to the primary view. Keep in mind that you need to maintain conditions specified within the ON clause for each temporal join (similar to what you have in each template).

<br>

